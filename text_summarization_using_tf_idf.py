# -*- coding: utf-8 -*-
"""Text Summarization using TF-IDF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oX9x0acz9IMzCUrhK24bDFgsm1PDJalq
"""

import pandas as pd
import numpy as np
import textwrap
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

nltk.download('stopwords')
nltk.download('punkt_tab')
nltk.download('wordnet')

!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv

df = pd.read_csv('bbc_text_cls.csv')

df.head()

df["labels"].hist()

sports_data = df[df.labels == "sport"]['text']
sports_data

def wrap(x):
  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)

print(wrap(sports_data.iloc[0]))

tokenized_senteneces = nltk.sent_tokenize(sports_data.iloc[0].split("\n", 1)[1])
tokenized_senteneces

vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), norm='l1')

model = vectorizer.fit_transform(tokenized_senteneces)
model

def get_sentence_score(tf_idf):
  all_non_zeros = tf_idf[tf_idf != 0]
  return all_non_zeros.mean()

scores = np.zeros(len(tokenized_senteneces))

for i in range(len(tokenized_senteneces)):
  score = get_sentence_score(model[i])
  scores[i] = score

scores

sort_idx = np.argsort(-scores)
sort_idx

print("Generate summary")

for i in sort_idx[:5]:
  print(wrap("%.2f: %s" % (scores[i], tokenized_senteneces[i])))

sports_data.iloc[0].split("\n", 1)[0]

def summaries(word):
  title = word.split("\n", 1)[0]
  word = word.split("\n", 1)[1]
  sentences = nltk.sent_tokenize(word)

  scores = np.zeros(len(sentences))

  for i in range(len(sentences)):
    score = get_sentence_score(vectorizer.fit_transform([sentences[i]]))
    scores[i] = score

  sort_idx = np.argsort(-scores)

  print("Title: ", title)
  print("Summary")
  for i in sort_idx[:5]:
    print(wrap(sentences[i]))

word = df[df.labels == 'politics']['text'].iloc[0]
summaries(word)

